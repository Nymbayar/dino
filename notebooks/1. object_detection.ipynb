{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import argparse\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from main_dino import *\n",
    "from custom_dataset import GerDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df = {'img_name' : [],'classes' : [],'x' : [],'y' : [],'width' : [],'height' : []}\n",
    "empty_list = []\n",
    "for idx,i in enumerate(os.listdir('kaggle/train/class/')):\n",
    "    ## Empty Labels\n",
    "    try:\n",
    "        tmp_df = pd.read_csv(f'kaggle/train/class/{i}',header=None)\n",
    "        for j in tmp_df[0].values:\n",
    "            annot_df['img_name'].append(f'kaggle/train/images/{i.split(\".\")[0]}.png')\n",
    "            annot_df['classes'].append(j.split()[0])\n",
    "            annot_df['x'].append(j.split()[1])\n",
    "            annot_df['y'].append(j.split()[2])\n",
    "            annot_df['width'].append(j.split()[3])\n",
    "            annot_df['height'].append(j.split()[4])\n",
    "    except pd.errors.EmptyDataError:\n",
    "        empty_list.append(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is 7 images which did not labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['07081.txt',\n",
       " '02528.txt',\n",
       " '04966.txt',\n",
       " '06229.txt',\n",
       " '04285.txt',\n",
       " '03798.txt',\n",
       " '02448.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check custom torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = GerDataset('kaggle/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/vscode/.cache/torch/hub/facebookresearch_xcit_main\n",
      "Will run the code on one GPU.\n",
      "| distributed init (rank 0): env://\n",
      "git:\n",
      "  sha: bff71b0b997d89b392bfde937841212e4922c821, status: has uncommited changes, branch: main\n",
      "\n",
      "arch: vit_base\n",
      "batch_size_per_gpu: 64\n",
      "clip_grad: 3.0\n",
      "data_path: kaggle/train\n",
      "dist_url: env://\n",
      "drop_path_rate: 0.1\n",
      "epochs: 100\n",
      "freeze_last_layer: 1\n",
      "global_crops_scale: (0.4, 1.0)\n",
      "gpu: 0\n",
      "local_crops_number: 8\n",
      "local_crops_scale: (0.05, 0.4)\n",
      "local_rank: 0\n",
      "lr: 0.0005\n",
      "min_lr: 1e-06\n",
      "momentum_teacher: 0.996\n",
      "norm_last_layer: True\n",
      "num_workers: 10\n",
      "optimizer: adamw\n",
      "out_dim: 65536\n",
      "output_dir: output/\n",
      "patch_size: 16\n",
      "rank: 0\n",
      "saveckp_freq: 20\n",
      "seed: 0\n",
      "teacher_temp: 0.04\n",
      "use_bn_in_head: False\n",
      "use_fp16: True\n",
      "warmup_epochs: 10\n",
      "warmup_teacher_temp: 0.04\n",
      "warmup_teacher_temp_epochs: 0\n",
      "weight_decay: 0.04\n",
      "weight_decay_end: 0.4\n",
      "world_size: 1\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:890: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "Data loaded: there are 2467 images.\n",
      "Student and Teacher are built: they are both vit_base network.\n",
      "Loss, optimizer and schedulers ready.\n",
      "Starting DINO training !\n",
      "Traceback (most recent call last):\n",
      "  File \"main_dino.py\", line 473, in <module>\n",
      "    train_dino(args)\n",
      "  File \"main_dino.py\", line 275, in train_dino\n",
      "    train_stats = train_one_epoch(student, teacher, teacher_without_ddp, dino_loss,\n",
      "  File \"main_dino.py\", line 308, in train_one_epoch\n",
      "    for it, (images, _) in enumerate(metric_logger.log_every(data_loader, 10, header)):\n",
      "  File \"/workspaces/dino/utils.py\", line 377, in log_every\n",
      "    for obj in iterable:\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1224, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1250, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/_utils.py\", line 457, in reraise\n",
      "    raise exception\n",
      "TypeError: Caught TypeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/workspaces/dino/custom_dataset.py\", line 48, in __getitem__\n",
      "    imagepil = PIL.Image.open(os.path.join(self.root,'images',self.imgs[idx])).convert('RGB')\n",
      "  File \"/opt/conda/lib/python3.8/posixpath.py\", line 90, in join\n",
      "    genericpath._check_arg_types('join', a, *p)\n",
      "  File \"/opt/conda/lib/python3.8/genericpath.py\", line 152, in _check_arg_types\n",
      "    raise TypeError(f'{funcname}() argument must be str, bytes, or '\n",
      "TypeError: join() argument must be str, bytes, or os.PathLike object, not 'list'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python main_dino.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
